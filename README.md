 Museum Parallax (AI-Enhanced Virtual Art Gallery)

 Overview

Versailles Museum Parallax is an immersive 3D virtual art gallery built with
Next.js + React Three Fiber + OpenAI GPT.
Users can walk through a gallery, view paintings, and interact with a virtual AI guide capable of:
	‚Ä¢	identifying artworks
	‚Ä¢	describing them
	‚Ä¢	zooming on request
	‚Ä¢	locating paintings by left/right/next
	‚Ä¢	answering questions naturally

The AI guide is connected to Langfuse, providing full MLOps observability, production monitoring, and trace visualization.


 Features

3D Gallery
	‚Ä¢	Full interactive scene in React Three Fiber
	‚Ä¢	Smooth camera movement
	‚Ä¢	Dynamic artworks with position + metadata
	‚Ä¢	Zoom-in animations

 AI Virtual Guide (Chatbot)
	‚Ä¢	Smart artwork detection
	‚Ä¢	Natural conversation
	‚Ä¢	‚ÄúZoom this artwork‚Äù ‚Üí triggers backend action
	‚Ä¢	‚ÄúWhat is the painting next to the Mona Lisa?‚Äù ‚Üí detection + response
	‚Ä¢	Multi-step dialogue with memory

 Smart Reasoning Pipeline
	‚Ä¢	Custom smartMatch() algorithm
	‚Ä¢	Fuzzy title matching
	‚Ä¢	Artist recognition
	‚Ä¢	Automatic fallback to GPT

 MLOps Monitoring (Langfuse)

Fully integrated observability for local AND production:
	‚Ä¢	Traces (full conversation view)
	‚Ä¢	Spans (smartMatch, OpenAI calls‚Ä¶)
	‚Ä¢	Events (zoom, left/right navigation, user actions)
	‚Ä¢	Inputs / outputs logged
	‚Ä¢	Errors captured

Everything is tracked both locally AND on Vercel deployment.



Technologies
	‚Ä¢	Next.js 15
	‚Ä¢	React Three Fiber
	‚Ä¢	OpenAI API
	‚Ä¢	Langfuse (monitoring & MLOps)
	‚Ä¢	Typescript
	‚Ä¢	Vercel Deployment



 Installation & Setup

1Ô∏è Clone the project

git clone <repo-url>
cd museum-parallax

2Ô∏è Install dependencies

npm install

If you have peer dependency conflicts:

npm install --legacy-peer-deps

3Ô∏è Add environment variables

Create .env.local :

OPENAI_API_KEY=sk-xxxx
LANGFUSE_SECRET_KEY=lfsk_xxx
LANGFUSE_PUBLIC_KEY=lfpk_xxx
LANGFUSE_BASE_URL=https://cloud.langfuse.com

 About Langfuse in Production

To enable MLOps monitoring on Vercel, add the same keys in:

Vercel ‚Üí Project ‚Üí Settings ‚Üí Environment Variables

Your chatbot will then be monitored in real-time on Langfuse, even for users on the deployed website.


‚ñ∂Ô∏è Run Locally

npm run dev

Visit:
üëâ http://localhost:3000

 Deployment

Deploy automatically with Vercel:
	‚Ä¢	Every commit to main triggers a deployment
	‚Ä¢	Environment variables must be added manually in Vercel
	‚Ä¢	Once deployed, all AI interactions are logged in Langfuse

 MLOps Integration (Langfuse)

 What is logged?

For every user message:
	‚Ä¢	A trace is created
	‚Ä¢	A generation span for the OpenAI call
	‚Ä¢	An event if the user asks to zoom / left / right
	‚Ä¢	A chatbot-response event with output
	‚Ä¢	A full timeline of user queries


 Project File Structure

app/
 ‚îú‚îÄ api/
 ‚îÇ   ‚îî‚îÄ chat/route.ts      # AI logic + Langfuse monitoring
 ‚îú‚îÄ components/
 ‚îÇ   ‚îú‚îÄ gallery-3d.tsx
 ‚îÇ   ‚îú‚îÄ artwork-mesh.tsx
 ‚îÇ   ‚îî‚îÄ chatbot.tsx
 ‚îú‚îÄ data/
 ‚îÇ   ‚îî‚îÄ artworks.ts
 ‚îî‚îÄ page.tsx
public/
 ‚îî‚îÄ images/


 route.ts (AI + Langfuse)

All AI reasoning and MLOps logging happens here:
	‚Ä¢	Smart artwork matching
	‚Ä¢	Direction detection (left/right/next to‚Ä¶)
	‚Ä¢	Zoom detection
	‚Ä¢	Description logic
	‚Ä¢	Trace creation
	‚Ä¢	Span recording
	‚Ä¢	Event logging





